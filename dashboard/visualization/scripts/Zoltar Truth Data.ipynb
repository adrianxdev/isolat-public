{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Zoltar Truth Data\n",
    "With JHU Truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymmwr as pm\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from zoltpy import util\n",
    "import json\n",
    "\n",
    "def get_epi_data(date):\n",
    "    format_str = '%m/%d/%y'  # The format\n",
    "    dt = datetime.datetime.strptime(date, format_str).date()\n",
    "    epi = pm.date_to_epiweek(dt)\n",
    "    return epi.year, epi.week, epi.day\n",
    "\n",
    "def get_epi_data_TZ(date):\n",
    "    format_str = '%Y-%m-%d'  # The format\n",
    "    dt = datetime.datetime.strptime(date, format_str).date()\n",
    "    epi = pm.date_to_epiweek(dt)\n",
    "    epi_week = epi.week\n",
    "    epi_day = epi.day\n",
    "    if epi_day >=3: # cut off is Tuesday\n",
    "        epi_week = epi_week + 1\n",
    "    return epi.year, epi_week, epi.day\n",
    "\n",
    "def get_available_timezeros(project_name):\n",
    "    conn = util.authenticate()\n",
    "    project = [project for project in conn.projects if project.name == project_name][0]\n",
    "    project_timezeros = project.timezeros\n",
    "    timezero = []\n",
    "    for timezero_array in project_timezeros:\n",
    "        timezero += [timezero_array.timezero_date]\n",
    "    return timezero\n",
    "\n",
    "\n",
    "def configure_JHU_data(df, target):\n",
    "    # convert matrix to repeating row format\n",
    "    df_truth = df.unstack()\n",
    "    df_truth = df_truth.reset_index()\n",
    "\n",
    "    # get epi data from date\n",
    "    df_truth['year'], df_truth['week'], df_truth['day'] = \\\n",
    "        zip(*df_truth['level_0'].map(get_epi_data))\n",
    "\n",
    "    # rename columns\n",
    "    df_truth = df_truth.rename(columns={0: \"value\",\n",
    "                                        \"level_1\": \"location_long\"})\n",
    "    \n",
    "    # Get state IDs\n",
    "    df_truth = df_truth.merge(fips_codes, left_on='location_long', right_on='state_name', how='left')\n",
    "    df_truth.loc[df_truth[\"location_long\"] == \"US\", \"state_code\"] = \"US\"\n",
    "    df_truth[\"state_code\"].replace({\"US\": 1000}, inplace=True)  # so that can be converted to int\n",
    "\n",
    "    # convert FIPS code to int\n",
    "    df_truth = df_truth.dropna(subset=['state_code'])\n",
    "    df_truth[\"state_code\"] = df_truth[\"state_code\"].astype(int)\n",
    "\n",
    "    # add leading zeros to state code\n",
    "    df_truth['state_code'] = df_truth['state_code'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "\n",
    "    # convert 1000 back to US\n",
    "    df_truth[\"state_code\"].replace({\"1000\": \"US\"}, inplace=True)\n",
    "    df_truth.loc[df_truth[\"location_long\"] == \"US\", \"state\"] = \"nat\"\n",
    "    \n",
    "    # Observed data on the seventh day\n",
    "    # or group by week for incident deaths\n",
    "    if target == 'Incident Deaths':\n",
    "        df_vis = df_truth.groupby(['week', 'location_long'], as_index=False).agg({'level_0': 'last',\n",
    "                                                                         'value': 'sum', \n",
    "                                                                         'year': 'last', \n",
    "                                                                         'day': 'last', \n",
    "                                                                         'state_code': 'last',\n",
    "                                                                         'state': 'last',\n",
    "                                                                         'state_name': 'last' })\n",
    "    else:\n",
    "        df_vis = df_truth\n",
    "    df_vis['week'] = df_vis['week'] + 1  # shift epiweek on axis\n",
    "    \n",
    "    # add leading zeros to epi week\n",
    "    df_vis['week'] = df_vis['week'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "\n",
    "    # define epiweek\n",
    "    df_vis['epiweek'] = df_vis['year'].astype(str) + df_vis['week']\n",
    "\n",
    "    # only output \"location\", \"epiweek\", \"value\"\n",
    "    df_vis = df_vis.rename(columns={\"state\": \"location\"})\n",
    "    \n",
    "    # rename location\n",
    "    df_truth_long = df_vis.rename(columns={\"week\": \"epiweek\",\n",
    "                                           \"state_code\": \"unit\",\n",
    "                                           \"level_0\": \"date\"})\n",
    "    # get timezero\n",
    "    df_truth_long['date'] = pd.to_datetime(df_truth_long['date'])\n",
    "    \n",
    "    # initialize df_targets\n",
    "    df_targets = pd.DataFrame(columns=list(df_truth_long.columns).append('target'))\n",
    "    \n",
    "    # use Saturday truth values\n",
    "    df_truth_values = df_truth_long[df_truth_long['day'] == 7]\n",
    "    \n",
    "    # find week-ahead targets\n",
    "    for i in range(4):\n",
    "        weeks_ahead = i + 1\n",
    "        days_back = 5 + ((weeks_ahead - 1) * 7)  # timezero is on Mondays\n",
    "\n",
    "        df_calc = df_truth_values  # initialize df\n",
    "\n",
    "        # find timezero and target\n",
    "        df_calc['timezero'] = df_calc['date'] - datetime.timedelta(days=days_back)\n",
    "        if target == \"Cumulative Deaths\":\n",
    "            df_calc['target'] = \"%i wk ahead cum death\" % weeks_ahead\n",
    "        else:\n",
    "            df_calc['target'] = \"%i wk ahead inc death\" % weeks_ahead\n",
    "        # concatenate truth\n",
    "        df_targets = pd.concat([df_targets, df_calc])\n",
    "    \n",
    "    # get epi data from Timezero\n",
    "    df_targets['timezero'] = df_targets['timezero'].astype(str)\n",
    "    df_targets['tz_year'], df_targets['tz_week'], df_targets['tz_day'] = \\\n",
    "        zip(*df_targets['timezero'].map(get_epi_data_TZ))\n",
    "    \n",
    "    # truth targets by timezero week\n",
    "    df_targets = df_targets[[\"tz_week\", \"unit\", \"target\", \"value\"]]\n",
    "    \n",
    "    # Map all timezeros in Zoltar to Corresponding weeks\n",
    "    df_map_wk_to_tz = pd.DataFrame(columns=['timezero'])\n",
    "    df_map_wk_to_tz['timezero'] = get_available_timezeros(\"COVID-19 Forecasts\")\n",
    "    df_map_wk_to_tz['tz_year'], df_map_wk_to_tz['tz_week'], df_map_wk_to_tz['tz_day'] = \\\n",
    "        zip(*df_map_wk_to_tz['timezero'].map(get_epi_data_TZ))\n",
    "    \n",
    "    # Merge timezeros with truth values and targets\n",
    "    df_final = pd.merge(df_targets, df_map_wk_to_tz, how='right', on=['tz_week'])\n",
    "    \n",
    "    # select columns\n",
    "    df_final = df_final[[\"timezero\", \"unit\", \"target\", \"value\"]]\n",
    "    \n",
    "    # drop empty rows\n",
    "    nan_value = float(\"NaN\")\n",
    "    df_final.replace(\"\", nan_value, inplace=True)\n",
    "    df_final.dropna(inplace=True)\n",
    "    return df_final\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\")\n",
    "fips_codes = pd.read_csv('../../template/state_fips_codes.csv')\n",
    "\n",
    "# aggregate by state and nationally\n",
    "state_agg = df.groupby(['Province_State']).sum()\n",
    "us_nat = df.groupby(['Country_Region']).sum()\n",
    "df_state_nat = state_agg.append(us_nat)\n",
    "\n",
    "# drop unnecessary columns\n",
    "cols = list(range(0, 6))\n",
    "df_truth = df_state_nat.drop(df_state_nat.columns[cols], axis=1)\n",
    "\n",
    "# calculate incidents from cumulative\n",
    "df_truth_cumulative = df_truth\n",
    "df_truth_incident = df_truth - df_truth.shift(periods=1, axis='columns') \n",
    "\n",
    "# re-format files\n",
    "df_cum_death = configure_JHU_data(df_truth_cumulative, \"Cumulative Deaths\")\n",
    "df_inc_death = configure_JHU_data(df_truth_incident, \"Incident Deaths\")\n",
    "\n",
    "# concatenate targers\n",
    "zoltar_truth = pd.concat([df_cum_death,df_inc_death])\n",
    "\n",
    "# write truth to csv\n",
    "file_path = '../../data-truth/zoltar-truth.csv'\n",
    "zoltar_truth.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
